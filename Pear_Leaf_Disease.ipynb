{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ba42383-ac53-4881-a706-7cf51e0f0e0a",
   "metadata": {},
   "source": [
    "MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebf9e0f1-15f3-49e6-863b-790c1e6d3adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "# Define image size\n",
    "IMG_SIZE = 224\n",
    "\n",
    "# Load the trained model\n",
    "model_path = 'C:/Users/milin/Downloads/7sem/Models/Mobilenet/mobilenet.keras'\n",
    "mobilenet_model = tf.keras.models.load_model(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be38ff8c-b3a6-42e4-9d8b-25e9e2659fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess the MobileNet image\n",
    "def load_and_preprocess_mobilenet_image(image_array):\n",
    "    image = tf.convert_to_tensor(image_array, dtype=tf.float32)\n",
    "    image = tf.image.resize(image, [224, 224])  # Resize to MobileNet size\n",
    "    image = image / 127.5 - 1.0  # Normalize to [-1, 1]\n",
    "    return tf.expand_dims(image, axis=0)  # Add batch dimension\n",
    "\n",
    "# Prediction function for MobileNet\n",
    "def predict_mobilenet(image_array, threshold=0.5):\n",
    "    image = load_and_preprocess_mobilenet_image(image_array)\n",
    "    start_time = time.time()\n",
    "    predictions = mobilenet_model.predict(image)[0]\n",
    "    prediction_time = time.time() - start_time\n",
    "    binary_predictions = (predictions >= threshold).astype(int)\n",
    "    return binary_predictions, prediction_time, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4340361b-328d-4b2c-b828-b0a65862c4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Prediction: [1.7749017e-09 9.9988419e-01 1.4834625e-03 3.3732235e-07 2.1335424e-08\n",
      " 3.1662304e-02 3.8362923e-05 9.9820167e-01 7.6346502e-02]\n",
      "Binary Output: [0 1 0 0 0 0 0 1 0]\n",
      "Prediction Time: 1.575439691543579\n"
     ]
    }
   ],
   "source": [
    "# New function to handle image path\n",
    "def predict_mobilenet_from_path(image_path, threshold=0.5):\n",
    "    # Load the image from the file path\n",
    "    image = Image.open(image_path).convert('RGB')  # Convert to RGB\n",
    "    image_array = np.array(image)  # Convert image to array\n",
    "    # Call the existing predict_mobilenet function\n",
    "    return predict_mobilenet(image_array, threshold)\n",
    "\n",
    "# Example usage with an image path\n",
    "new_image_path = 'C:/Users/milin/Downloads/7sem/Pear/leaves/u956.jpg'\n",
    "binary_output, prediction_time, predictions = predict_mobilenet_from_path(new_image_path)  # Call with image path\n",
    "print(\"Prediction:\", predictions)\n",
    "print(\"Binary Output:\", binary_output)\n",
    "print(\"Prediction Time:\", prediction_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0e121d-b474-4ad6-b583-b6f1a148bc89",
   "metadata": {},
   "source": [
    "Rathi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ec2e291-eb41-4ca6-bdfa-734320cdd92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Define image size\n",
    "IMG_SIZE = 329\n",
    "\n",
    "# Load the trained model (update model path as needed)\n",
    "model_path = 'C:/Users/milin/Downloads/7sem/Models/Inception/Inception_model2.keras'\n",
    "inception_model = tf.keras.models.load_model(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4bc59cf-5ee0-4c31-803c-6453c439880a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess the Inception image\n",
    "def load_and_preprocess_inception_image(img_array):\n",
    "    img = tf.image.resize(img_array, [329, 329])  # Resize to Inception size\n",
    "    img = img / 255.0  # Normalize to [0, 1]\n",
    "    return tf.expand_dims(img, axis=0)  # Add batch dimension\n",
    "\n",
    "# Prediction function for Inception\n",
    "def predict_inception(img_array):\n",
    "    img_array = load_and_preprocess_inception_image(img_array)\n",
    "    start_time = time.time()\n",
    "    predictions = inception_model.predict(img_array)\n",
    "    prediction_time = time.time() - start_time\n",
    "\n",
    "    # Identify the index of the maximum probability for each subset\n",
    "    max_idx_first_four = np.argmax(predictions[0][:4])\n",
    "    max_idx_last_five = np.argmax(predictions[0][4:]) + 4  # Shift index for last five\n",
    "\n",
    "    # Create binary labels with exactly one '1' for each subset\n",
    "    binary_predictions = np.zeros_like(predictions[0], dtype=int)\n",
    "    binary_predictions[max_idx_first_four] = 1\n",
    "    binary_predictions[max_idx_last_five] = 1\n",
    "\n",
    "    return binary_predictions, prediction_time, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36db626d-4fdf-469f-a873-543d273b1585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Prediction: [[5.5940519e-09 1.7219891e-03 9.9630487e-01 3.2067874e-08 1.5679600e-08\n",
      "  1.4406337e-03 9.1521523e-04 5.7181008e-02 9.6395189e-01]]\n",
      "Binary Output: [0 0 1 0 0 0 0 0 1]\n",
      "Prediction Time: 2.4575676918029785\n"
     ]
    }
   ],
   "source": [
    "# New function to handle image path\n",
    "def predict_inception_from_path(image_path):\n",
    "    # Load the image from the file path\n",
    "    image = Image.open(image_path).convert('RGB')  # Convert to RGB\n",
    "    image_array = np.array(image)  # Convert image to array\n",
    "    # Call the existing predict_inception function\n",
    "    return predict_inception(image_array)\n",
    "\n",
    "# Example usage with an image path\n",
    "new_image_path = 'C:/Users/milin/Downloads/7sem/Pear/leaves/u644.jpg'\n",
    "binary_output, prediction_time, predictions = predict_inception_from_path(new_image_path)  # Call with image path\n",
    "print(\"Prediction:\", predictions)\n",
    "print(\"Binary Output:\", binary_output)\n",
    "print(\"Prediction Time:\", prediction_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e351ee5-33ae-4dbc-901f-85200cdda1c8",
   "metadata": {},
   "source": [
    "Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e690f65-9cf6-4740-80bb-68cda88cf415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image size\n",
    "IMG_SIZE = 224\n",
    "\n",
    "# Load the trained model (update model path as needed)\n",
    "model_path = 'C:/Users/milin/Downloads/7sem/Models/Resnet/resnet_model2.keras'\n",
    "resnet_model = tf.keras.models.load_model(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b24b2744-f1c0-4972-ae9e-77bf11493711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess the ResNet image\n",
    "def load_and_preprocess_resnet_image(img_array):\n",
    "    img = tf.image.resize(img_array, [224, 224])  # Resize to ResNet input size\n",
    "    img = img / 255.0  # Normalize to [0, 1]\n",
    "    return tf.expand_dims(img, axis=0)  # Add batch dimension\n",
    "\n",
    "# Prediction function for ResNet\n",
    "def predict_resnet(img_array):\n",
    "    img_array = load_and_preprocess_resnet_image(img_array)\n",
    "    start_time = time.time()\n",
    "    predictions = resnet_model.predict(img_array)\n",
    "    prediction_time = time.time() - start_time\n",
    "\n",
    "    # Identify the index of the maximum probability for each subset\n",
    "    max_idx_first_four = np.argmax(predictions[0][:4])\n",
    "    max_idx_last_five = np.argmax(predictions[0][4:]) + 4  # Shift index for last five\n",
    "\n",
    "    # Create binary labels with exactly one '1' for each subset\n",
    "    binary_predictions = np.zeros_like(predictions[0], dtype=int)\n",
    "    binary_predictions[max_idx_first_four] = 1\n",
    "    binary_predictions[max_idx_last_five] = 1\n",
    "\n",
    "    return binary_predictions, prediction_time, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2435a781-1e48-4c5e-84fd-6b1626cd5bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Prediction: [[4.9493875e-04 3.9127791e-01 5.5042171e-01 1.0281773e-02 5.7943357e-04\n",
      "  3.2722527e-01 2.0601933e-01 1.0129089e-01 1.3690901e-01]]\n",
      "Binary Output: [0 0 1 0 0 1 0 0 0]\n",
      "Prediction Time: 1.7837505340576172\n"
     ]
    }
   ],
   "source": [
    "# Function to handle image path for ResNet\n",
    "def predict_resnet_from_path(image_path):\n",
    "    # Load the image from the file path\n",
    "    image = Image.open(image_path).convert('RGB')  # Convert to RGB\n",
    "    image_array = np.array(image)  # Convert image to array\n",
    "    # Call the existing predict_resnet function\n",
    "    return predict_resnet(image_array)\n",
    "\n",
    "# Example usage with an image path\n",
    "new_image_path = 'C:/Users/milin/Downloads/7sem/Pear/leaves/u644.jpg'\n",
    "binary_output, prediction_time, predictions = predict_resnet_from_path(new_image_path)  # Call with image path\n",
    "print(\"Prediction:\", predictions)\n",
    "print(\"Binary Output:\", binary_output)\n",
    "print(\"Prediction Time:\", prediction_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd67c153-1244-41f0-b349-481cca5aeb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Define class names for predictions\n",
    "class_names = ['healthy', 'pear_slug', 'leaf_spot', 'curl', \n",
    "               'S0', 'S1', 'S2', 'S3', 'S4']\n",
    "\n",
    "# Gradio function for making predictions\n",
    "def gradio_predict(image):\n",
    "    # Get predictions from all three models\n",
    "    mobilenet_binary, mobilenet_time, mobilenet_predictions = predict_mobilenet(image)\n",
    "    inception_binary, inception_time, inception_predictions = predict_inception(image)\n",
    "    resnet_binary, resnet_time, resnet_predictions = predict_resnet(image)\n",
    "\n",
    "    # Map binary outputs to class names\n",
    "    mobilenet_classes = [class_names[i] for i in range(len(mobilenet_binary)) if mobilenet_binary[i] == 1]\n",
    "    inception_classes = [class_names[i] for i in range(len(inception_binary)) if inception_binary[i] == 1]\n",
    "    resnet_classes = [class_names[i] for i in range(len(resnet_binary)) if resnet_binary[i] == 1]\n",
    "\n",
    "    # Prepare output messages\n",
    "    mobilenet_output = (\n",
    "        f\"MobileNet Predicted Classes: {', '.join(mobilenet_classes)}\\n\"\n",
    "        f\"Binary Output: {mobilenet_binary}\\n\"\n",
    "        f\"Prediction Time: {mobilenet_time:.4f} seconds\"\n",
    "    )\n",
    "    \n",
    "    inception_output = (\n",
    "        f\"Inception Predicted Classes: {', '.join(inception_classes)}\\n\"\n",
    "        f\"Binary Output: {inception_binary}\\n\"\n",
    "        f\"Prediction Time: {inception_time:.4f} seconds\"\n",
    "    )\n",
    "\n",
    "    resnet_output = (\n",
    "        f\"ResNet Predicted Classes: {', '.join(resnet_classes)}\\n\"\n",
    "        f\"Binary Output: {resnet_binary}\\n\"\n",
    "        f\"Prediction Time: {resnet_time:.4f} seconds\"\n",
    "    )\n",
    "\n",
    "    # Ensemble predictions by averaging across models\n",
    "    ensemble_predictions = (mobilenet_predictions + inception_predictions + resnet_predictions) / 3\n",
    "    if len(ensemble_predictions.shape) > 1:\n",
    "        ensemble_predictions = ensemble_predictions.flatten()\n",
    "\n",
    "    # Determine the top class in each subset for the ensemble\n",
    "    max_prob_first_4 = max(ensemble_predictions[:4])\n",
    "    max_prob_last_5 = max(ensemble_predictions[4:])\n",
    "    \n",
    "    # Find corresponding classes\n",
    "    class_first_4 = class_names[np.argmax(ensemble_predictions[:4])]\n",
    "    class_last_5 = class_names[4 + np.argmax(ensemble_predictions[4:])]\n",
    "\n",
    "    # Ensemble output message\n",
    "    ensemble_output = (\n",
    "        f\"Disease : ({class_first_4}) ({max_prob_first_4:.4f})\\n\"\n",
    "        f\"Severity: ({class_last_5}) ({max_prob_last_5:.4f})\"\n",
    "    )\n",
    "\n",
    "    # Create probability graphs\n",
    "    mobilenet_plot = create_probability_plot(mobilenet_predictions, \"MobileNet Predictions\")\n",
    "    inception_plot = create_probability_plot(inception_predictions, \"Inception Predictions\")\n",
    "    resnet_plot = create_probability_plot(resnet_predictions, \"ResNet Predictions\")\n",
    "    ensemble_plot = create_probability_plot(ensemble_predictions, \"Ensemble Predictions\")\n",
    "\n",
    "    return mobilenet_output, inception_output, resnet_output, ensemble_output, mobilenet_plot, inception_plot, resnet_plot, ensemble_plot\n",
    "\n",
    "\n",
    "# Function to create probability plots with custom styling\n",
    "def create_probability_plot(predictions, model_name):\n",
    "    # Flatten predictions if necessary\n",
    "    if len(predictions.shape) > 1:\n",
    "        predictions = predictions.flatten()\n",
    "\n",
    "    # Plotting with customizations\n",
    "    plt.figure(figsize=(8, 4), facecolor='none')\n",
    "    plt.bar(class_names, predictions, color='#e86100')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title(f'{model_name} Probability Distribution', fontsize=14, color='white', fontweight='bold')\n",
    "    plt.xlabel('Classes', fontsize=12, color='white', fontweight='bold')\n",
    "    plt.ylabel('Probability', fontsize=12, color='white', fontweight='bold')\n",
    "    plt.xticks(rotation=45, color='white', fontweight='bold')\n",
    "    plt.yticks(color='white', fontweight='bold')\n",
    "    plt.gca().spines[:].set_visible(False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot to a file\n",
    "    plot_file = f\"{model_name.lower().replace(' ', '_')}_probabilities.png\"\n",
    "    plt.savefig(plot_file, transparent=True)\n",
    "    plt.close()\n",
    "    return plot_file\n",
    "\n",
    "# Set up Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn=gradio_predict,\n",
    "    inputs=gr.Image(type=\"numpy\"),\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"MobileNet Prediction Output\"),\n",
    "        gr.Textbox(label=\"Inception Prediction Output\"),\n",
    "        gr.Textbox(label=\"ResNet Prediction Output\"),\n",
    "        gr.Textbox(label=\"Ensemble Prediction Output\"),\n",
    "        gr.Image(label=\"MobileNet Probability Plot\"),\n",
    "        gr.Image(label=\"Inception Probability Plot\"),\n",
    "        gr.Image(label=\"ResNet Probability Plot\"),\n",
    "        gr.Image(label=\"Ensemble Probability Plot\")\n",
    "    ],\n",
    "    title=\"Pear Leaf Disease and Severity Prediction with Ensemble\",\n",
    "    description=\"Upload an image of a pear leaf to get predictions from MobileNet, Inception, ResNet, and an Ensemble model.\",\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "interface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ec9bcd-0a60-4a7b-828d-64057e8a1eee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
